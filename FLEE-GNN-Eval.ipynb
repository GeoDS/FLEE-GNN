{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FLEE-GNN - Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## resilience prediction with trained model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(data_path='./data/2012_data.csv', info_dir='./data/info/', label_path='./data/2012_label.csv', model_path='./weights/test0707/fl_model_round_18.pth', output_dir='./training/fl_noise_output_02_0707/')\n",
      "Namespace(info_dir='./data/info/', output_dir='./training/fl_noise_output_02_0707/', predict_label_path='./training/fl_noise_output_02_0707/predict.csv', true_label_path='./data/2012_label.csv')\n"
     ]
    }
   ],
   "source": [
    "! python ./scripts/evaluation.py --info-dir ./data/info/ --data-path ./data/2012_data.csv --label-path ./data/2012_label.csv --model-path ./weights/test0707/fl_model_round_18.pth --output-dir ./training/fl_noise_output_02_0707/\n",
    "! python ./scripts/plot_resilience.py --true-label-path ./data/2012_label.csv --predict-label-path ./training/fl_noise_output_02_0707/predict.csv --info-dir ./data/info/ --output-dir ./training/fl_noise_output_02_0707/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load ground truth and predicted resilience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = pd.read_csv('./data/2012_label.csv')\n",
    "gt_import_resilience = gt['import_resilience'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "fl_pred = pd.read_csv('./training/fl_noise_output_02_0707/predict.csv', header=None)\n",
    "fl_pred_import_resilience = fl_pred.values.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT-PRED MSE:  0.011883658770327488\n"
     ]
    }
   ],
   "source": [
    "# mean squared error\n",
    "print(\"GT-PRED MSE: \", ((gt_import_resilience - fl_pred_import_resilience) ** 2).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top-k coincidence rate\n",
    "def get_coincidence_rate_topk(gt, pred, top_k):\n",
    "    gt1 = gt[(~np.isnan(gt)) & (~np.isnan(pred))]\n",
    "    pred1 = pred[(~np.isnan(gt)) & (~np.isnan(pred))]\n",
    "    total = gt1.shape[0]\n",
    "    selected = top_k # int(np.ceil(top_pick * total))\n",
    "#     print(f'selected samples at top {top_k}: {selected}')\n",
    "    cutoff_gt = sorted(gt1, reverse=True)[selected - 1]\n",
    "    cutoff_pred = sorted(pred1, reverse=True)[selected - 1]\n",
    "#     print(f'cutoff_gt: {cutoff_gt}')\n",
    "#     print(f'cutoff_pred: {cutoff_pred}')\n",
    "    ind_selected_by_gt = np.where(gt1 >= cutoff_gt)[0]\n",
    "    ind_selected_by_both = np.where((gt1 >= cutoff_gt) & (pred1 >= cutoff_pred))[0]\n",
    "    return len(ind_selected_by_both) / len(ind_selected_by_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected samples at top 5: 0.4\n"
     ]
    }
   ],
   "source": [
    "top_k = 5\n",
    "print(f'selected samples at top {top_k}: {get_coincidence_rate_topk(gt_import_resilience, fl_pred_import_resilience, top_k)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected samples at top 10: 0.3\n"
     ]
    }
   ],
   "source": [
    "top_k = 10\n",
    "print(f'selected samples at top {top_k}: {get_coincidence_rate_topk(gt_import_resilience, fl_pred_import_resilience, top_k)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected samples at top 20: 0.7\n"
     ]
    }
   ],
   "source": [
    "top_k = 20\n",
    "print(f'selected samples at top {top_k}: {get_coincidence_rate_topk(gt_import_resilience, fl_pred_import_resilience, top_k)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected samples at top 30: 0.9\n"
     ]
    }
   ],
   "source": [
    "top_k = 30\n",
    "print(f'selected samples at top {top_k}: {get_coincidence_rate_topk(gt_import_resilience, fl_pred_import_resilience, top_k)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top% coincidence rate\n",
    "def get_coincidence_rate(gt, pred, top_pick):\n",
    "    gt1 = gt[(~np.isnan(gt)) & (~np.isnan(pred))]\n",
    "    pred1 = pred[(~np.isnan(gt)) & (~np.isnan(pred))]\n",
    "    total = gt1.shape[0]\n",
    "    selected = int(np.ceil(top_pick * total))\n",
    "#     print(f'selected samples at top pick rate {top_pick}: {selected}')\n",
    "    cutoff_gt = sorted(gt1, reverse=True)[selected - 1]\n",
    "    cutoff_pred = sorted(pred1, reverse=True)[selected - 1]\n",
    "#     print(f'cutoff_gt: {cutoff_gt}')\n",
    "#     print(f'cutoff_pred: {cutoff_pred}')\n",
    "    ind_selected_by_gt = np.where(gt1 >= cutoff_gt)[0]\n",
    "    ind_selected_by_both = np.where((gt1 >= cutoff_gt) & (pred1 >= cutoff_pred))[0]\n",
    "    return len(ind_selected_by_both) / len(ind_selected_by_gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected samples at top rate 0.1: 0.5\n"
     ]
    }
   ],
   "source": [
    "top_pick = 0.1\n",
    "print(f'selected samples at top rate {top_pick}: {get_coincidence_rate(gt_import_resilience, fl_pred_import_resilience, top_pick)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected samples at top rate 0.2: 0.36363636363636365\n"
     ]
    }
   ],
   "source": [
    "top_pick = 0.2\n",
    "print(f'selected samples at top rate {top_pick}: {get_coincidence_rate(gt_import_resilience, fl_pred_import_resilience, top_pick)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected samples at top rate 0.3: 0.6875\n"
     ]
    }
   ],
   "source": [
    "top_pick = 0.3\n",
    "print(f'selected samples at top rate {top_pick}: {get_coincidence_rate(gt_import_resilience, fl_pred_import_resilience, top_pick)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected samples at top rate 0.5: 0.8076923076923077\n"
     ]
    }
   ],
   "source": [
    "top_pick = 0.5\n",
    "print(f'selected samples at top rate {top_pick}: {get_coincidence_rate(gt_import_resilience, fl_pred_import_resilience, top_pick)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pearson R and spearman R\n",
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT-PRED Pearson R:  PearsonRResult(statistic=0.6204021270823173, pvalue=1.1979312456057458e-06)\n"
     ]
    }
   ],
   "source": [
    "print(\"GT-PRED Pearson R: \", pearsonr(gt_import_resilience, fl_pred_import_resilience))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT-PRED Spearman R:  SpearmanrResult(correlation=0.7302262443438913, pvalue=1.1940215101603559e-09)\n"
     ]
    }
   ],
   "source": [
    "print(\"GT-PRED Spearman R: \", spearmanr(gt_import_resilience, fl_pred_import_resilience))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## evaluation metrics for silo-wise centralized training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "west_pred = pd.read_csv('./training/noise_output_region_WEST_0.2/predict.csv', header=None)\n",
    "south_pred = pd.read_csv('./training/noise_output_region_SOUTH_0.2/predict.csv', header=None)\n",
    "midwest_pred = pd.read_csv('./training/noise_output_region_MIDWEST_0.2/predict.csv', header=None)\n",
    "northeast_pred = pd.read_csv('./training/noise_output_region_NORTHEAST_0.2/predict.csv', header=None)\n",
    "west_pred_import_resilience = west_pred.values.flatten()\n",
    "south_pred_import_resilience = south_pred.values.flatten()\n",
    "midwest_pred_import_resilience = midwest_pred.values.flatten()\n",
    "northeast_pred_import_resilience = northeast_pred.values.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GT-PRED WEST MSE:  0.04153002378279612\n",
      "GT-PRED SOUTH MSE:  0.007603086703278956\n",
      "GT-PRED MIDWEST MSE:  0.005931676752481813\n",
      "GT-PRED NORTHEAST MSE:  0.02984800399735259\n"
     ]
    }
   ],
   "source": [
    "# MSE\n",
    "print(\"GT-PRED WEST MSE: \", ((gt_import_resilience - west_pred_import_resilience) ** 2).mean())\n",
    "print(\"GT-PRED SOUTH MSE: \", ((gt_import_resilience - south_pred_import_resilience) ** 2).mean())\n",
    "print(\"GT-PRED MIDWEST MSE: \", ((gt_import_resilience - midwest_pred_import_resilience) ** 2).mean())\n",
    "print(\"GT-PRED NORTHEAST MSE: \", ((gt_import_resilience - northeast_pred_import_resilience) ** 2).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:neo4j]",
   "language": "python",
   "name": "conda-env-neo4j-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
